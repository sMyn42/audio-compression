{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import ffmpeg\n",
    "from pydub import AudioSegment\n",
    "from scipy.signal import find_peaks\n",
    "from tempfile import TemporaryDirectory\n",
    "import pyogg\n",
    "import soundfile\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d95bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path):\n",
    "    return AudioSegment.from_file(file_path, format=\"flac\")\n",
    "\n",
    "def compute_spectral_centroids(audio, sr=22050, frame_length=2048, hop_length=512):\n",
    "    samples = np.array(audio.get_array_of_samples()).astype(np.float32)\n",
    "    y = librosa.util.normalize(samples)\n",
    "    centroids = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=hop_length)[0]\n",
    "    return centroids\n",
    "\n",
    "def segment_audio(centroids, threshold=1.5):\n",
    "    # Compute difference of spectral centroid across frames\n",
    "    diff = np.abs(np.diff(centroids))\n",
    "    peaks, _ = find_peaks(diff, height=threshold * np.std(diff))\n",
    "    return peaks\n",
    "\n",
    "def assign_bitrates(centroids, peaks, low=64000, mid=96000, high=128000):\n",
    "    bitrates = []\n",
    "    split_centroids = np.split(centroids, peaks)\n",
    "    for seg in split_centroids:\n",
    "        avg = np.mean(seg)\n",
    "        if avg < 2000:\n",
    "            bitrates.append(low)\n",
    "        elif avg < 4000:\n",
    "            bitrates.append(mid)\n",
    "        else:\n",
    "            bitrates.append(high)\n",
    "    return bitrates\n",
    "\n",
    "def split_audio(audio, peaks, frame_duration_ms):\n",
    "    segments = []\n",
    "    start = 0\n",
    "    for peak in peaks:\n",
    "        end = peak * frame_duration_ms\n",
    "        segments.append(audio[start:end])\n",
    "        start = end\n",
    "    segments.append(audio[start:])  # final segment\n",
    "    return segments\n",
    "\n",
    "def encode_segment_to_aac(segment, bitrate, path):\n",
    "    segment.export(path, format=\"wav\")\n",
    "    aac_path = path.replace(\".wav\", \".m4a\")\n",
    "    ffmpeg.input(path).output(aac_path, audio_bitrate=f\"{bitrate}k\", acodec=\"aac\").run(overwrite_output=True, quiet=True)\n",
    "    return aac_path\n",
    "\n",
    "def concatenate_aac_segments(paths, output_path):\n",
    "    txt_list_path = os.path.join(os.path.dirname(paths[0]), \"concat_list.txt\")\n",
    "    with open(txt_list_path, \"w\") as f:\n",
    "        for p in paths:\n",
    "            f.write(f\"file '{p}'\\n\")\n",
    "    ffmpeg.input(txt_list_path, format='concat', safe=0).output(output_path, acodec='copy').run(overwrite_output=True)\n",
    "\n",
    "def vbr_compress(input_flac, output_path):\n",
    "    ffmpeg.input(input_flac).output(output_path, acodec='aac', audio_bitrate='0', compression_level='5').run(overwrite_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_encode(input_flac, output_adaptive, output_vbr):\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        print(\"[*] Loading audio...\")\n",
    "        audio = load_audio(input_flac)\n",
    "        centroids = compute_spectral_centroids(audio)\n",
    "        peaks = segment_audio(centroids)\n",
    "        frame_duration_ms = len(audio) / len(centroids)\n",
    "        segments = split_audio(audio, peaks, frame_duration_ms)\n",
    "        bitrates = assign_bitrates(centroids, peaks)\n",
    "\n",
    "        print(\"[*] Encoding segments...\")\n",
    "        segment_paths = []\n",
    "        for i, (segment, br) in enumerate(zip(segments, bitrates)):\n",
    "            temp_wav = os.path.join(tempdir, f\"seg_{i}.wav\")\n",
    "            aac_path = encode_segment_to_aac(segment, br, temp_wav)\n",
    "            segment_paths.append(aac_path)\n",
    "\n",
    "        print(\"[*] Concatenating segments...\")\n",
    "        concatenate_aac_segments(segment_paths, output_adaptive)\n",
    "\n",
    "        print(\"[*] Encoding baseline VBR...\")\n",
    "        vbr_compress(input_flac, output_vbr)\n",
    "\n",
    "        print(\"[✓] Done.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82229796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio = load_audio(\"HIT THE FLOOR.flac\")\n",
    "raw, sr = librosa.load(\"HIT THE FLOOR.flac\", sr=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd7193",
   "metadata": {},
   "source": [
    "# May 7th\n",
    "\n",
    "## Approach\n",
    "\n",
    "1. Try splitting one song in two and then stitch and listen through\n",
    "2. Try using genre data to create an ideal predictor\n",
    "3. Envision an ideal predictor, and what it would contribute to the algorithm?\n",
    "4. Compute waveform metrics for the []\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "half = len(audio) // 2\n",
    "audio1 = audio[:half]\n",
    "audio2 = audio[half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb27cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1.export(\"first_half.aac\", format=\"adts\")\n",
    "audio2.export(\"second_half.aac\", format=\"adts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.export(\"full_audio.aac\", format=\"adts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7920f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Create the concat list file\n",
    "with open(\"aac_list.txt\", \"w\") as f:\n",
    "    f.write(\"file 'first_half.aac'\\n\")\n",
    "    f.write(\"file 'second_half.aac'\\n\")\n",
    "\n",
    "# Run ffmpeg command\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\",\n",
    "    \"-i\", \"aac_list.txt\", \"-c\", \"copy\", \"stitched_output.aac\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import zlib\n",
    "\n",
    "\n",
    "def load_compress_audio(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    sr_target: int = 16000,\n",
    "    n_fft: int = 1024,\n",
    "    hop_length: int = 512,\n",
    "    keep_bins: int = 100\n",
    "):\n",
    "    \"\"\"\n",
    "    Compress an audio file into a proprietary format that mimics AAC compression.\n",
    "\n",
    "    Parameters:\n",
    "        input_path (str): Path to the input audio file (e.g., .flac, .wav).\n",
    "        output_path (str): Path to save the compressed binary file (.mycmp).\n",
    "        sr_target (int): Target sample rate for downsampling.\n",
    "        n_fft (int): FFT window size.\n",
    "        hop_length (int): Hop length for STFT.\n",
    "        keep_bins (int): Number of frequency bins to keep (controls compression level).\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(input_path, sr=sr_target)\n",
    "    stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    magnitude = np.abs(stft)\n",
    "\n",
    "    # Normalize and keep only lower frequency bins\n",
    "    compressed = magnitude[:keep_bins, :]\n",
    "    max_val = np.max(compressed) or 1.0  # Avoid divide by zero\n",
    "    quantized = np.round(compressed / max_val * 255).astype(np.uint8)\n",
    "\n",
    "    # Pack header + audio data\n",
    "    header = np.array([sr_target, n_fft, hop_length, keep_bins, compressed.shape[1]], dtype=np.int32)\n",
    "    data = np.concatenate([header.view(np.uint8), quantized.flatten()])\n",
    "\n",
    "    # Compress and save\n",
    "    packed = zlib.compress(data)\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(packed)\n",
    "\n",
    "    return y, sr\n",
    "\n",
    "\n",
    "def decompress_audio(\n",
    "    input_path: str\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Decompress a proprietary audio format back into a waveform.\n",
    "\n",
    "    Parameters:\n",
    "        input_path (str): Path to the compressed binary file (.mycmp).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Reconstructed audio waveform (mono).\n",
    "    \"\"\"\n",
    "    with open(input_path, 'rb') as f:\n",
    "        packed = f.read()\n",
    "\n",
    "    data = zlib.decompress(packed)\n",
    "\n",
    "    # Extract header\n",
    "    header_size = 5 * 4  # 5 int32s\n",
    "    header = np.frombuffer(data[:header_size], dtype=np.int32)\n",
    "    sr, n_fft, hop_length, keep_bins, n_frames = header\n",
    "\n",
    "    # Extract and reshape audio data\n",
    "    quantized = np.frombuffer(data[header_size:], dtype=np.uint8)\n",
    "    magnitude = quantized.astype(np.float32).reshape((keep_bins, n_frames)) / 255.0\n",
    "\n",
    "    # Reconstruct full STFT frame (zero-pad high frequencies)\n",
    "    stft_shape = (n_fft // 2 + 1, n_frames)\n",
    "    full_stft = np.zeros(stft_shape, dtype=np.float32)\n",
    "    full_stft[:keep_bins, :] = magnitude\n",
    "\n",
    "    # Inverse STFT\n",
    "    waveform = librosa.istft(full_stft, hop_length=hop_length)\n",
    "    return waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ccffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio = \"HIT THE FLOOR.flac\"\n",
    "compressed_file = \"example.mycmp\"\n",
    "output_audio = \"reconstructed.wav\"\n",
    "\n",
    "# Compress\n",
    "x, sr = load_compress_audio(input_audio, compressed_file)\n",
    "\n",
    "# Decompress\n",
    "y = decompress_audio(compressed_file)\n",
    "\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "sf.write(output_audio, y, samplerate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.pad(y, (0, x.shape[0] - y.shape[0]), constant_values=[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb79647",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a46113",
   "metadata": {},
   "source": [
    "# Similar Attempt with PyOgg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea46cd68",
   "metadata": {},
   "source": [
    "## Strategies\n",
    "\n",
    "What PyOgg Currently Does with the Opus Codec\n",
    "\n",
    "\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366be25",
   "metadata": {},
   "source": [
    "## Viewing the Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf718ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbc518",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw, sr = librosa.load(\"HIT THE FLOOR.flac\", sr=None, mono=False)\n",
    "print(raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd262bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 1200 // 6\n",
    "hop_length = 600 // 6\n",
    "win_length = n_fft // 6\n",
    "window = 'hann'\n",
    "\n",
    "raw_spec = librosa.stft(raw, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_cutoff = 800\n",
    "split_cutoff = 125\n",
    "\n",
    "total_spec = np.copy(raw_spec)\n",
    "raw_spec[:, hf_cutoff:, :] = np.mean(raw_spec[:, hf_cutoff:, :], axis=(0, 1))\n",
    "raw_hf_spec = np.copy(raw_spec)\n",
    "raw_spec[:, split_cutoff:, :] = 0\n",
    "raw_hf_spec[:, :split_cutoff, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be7dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_raw = librosa.istft(raw_spec, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window, length=raw.shape[1])\n",
    "edited_hf = librosa.istft(raw_hf_spec, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window, length=raw.shape[1])\n",
    "edited_total = librosa.istft(total_spec, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window, length=raw.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw - (edited_hf + edited_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d492d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hf_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab06429",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hf_spec.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(raw_hf_spec.mean(axis=0), sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13047b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning algorithm to strip irrelevancies from HF noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hf_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9baf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 8 bit prediction to fill in the noise\n",
    "\n",
    "# Imagine we have a predictor that can predict, based on the tempo of the song (given the )\n",
    "\n",
    "# Use percentile cutoff to quantize noise\n",
    "\n",
    "# HF-noise usually spread in sound stage, we neglect this for now, but can arbitrarily be placed further to one side after this algorithm takes place\n",
    "a_raw_hf_spec = raw_hf_spec.mean(axis=0)\n",
    "P = 20\n",
    "\n",
    "# Smoothing quantizes all \"noise\" or signal below the 75th percentile of \n",
    "cutoff = np.percentile(np.abs(a_raw_hf_spec), P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bee4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_lower_pow10(x):\n",
    "    return 10 ** np.floor(np.log10(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_raw_hf_spec = np.where(\n",
    "    a_raw_hf_spec < cutoff,\n",
    "    nearest_lower_pow10(np.abs(a_raw_hf_spec)),\n",
    "    np.abs(a_raw_hf_spec)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_raw_hf_spec[a_raw_hf_spec < 1e-9] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_raw_hf_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9082bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hf_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02248529",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_a_hf = librosa.istft(a_raw_hf_spec, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window, length=raw.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dfd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_a_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b0be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soundfile.write(\"edited_hit_the_floor.wav\", (edited_raw + edited_hf).T, sr)\n",
    "soundfile.write(\"q_edited_hit_the_floor.wav\", (edited_raw + edited_a_hf).T, sr)\n",
    "soundfile.write(\"hit_the_floor.wav\", raw.T, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR\n",
    "\n",
    "def calculate_snr_from_arrays(clean, noisy):\n",
    "    \"\"\"\n",
    "    Assumes:\n",
    "    - clean: NumPy array of clean signal\n",
    "    - noisy: NumPy array of noisy or degraded signal\n",
    "    - Both are same shape and dtype\n",
    "    \"\"\"\n",
    "    clean = clean.astype(np.float32)\n",
    "    noisy = noisy.astype(np.float32)\n",
    "\n",
    "    noise = clean - noisy\n",
    "    signal_power = np.sum(clean ** 2)\n",
    "    noise_power = np.sum(noise ** 2)\n",
    "\n",
    "    print(signal_power)\n",
    "    print(noise_power)\n",
    "\n",
    "    snr = 10 * np.log10((signal_power) / (noise_power))  # Avoid division by zero\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e52862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_snr_from_arrays(edited_a_hf + edited_raw, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60005c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress to see where gains are made by removing c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215bc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", \"hit_the_floor.wav\",\n",
    "    \"-c:a\", \"libopus\",\n",
    "    \"-b:a\", \"96k\",  # bitrate\n",
    "    \"hit_the_floor.opus\"\n",
    "])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", \"edited_hit_the_floor.wav\",\n",
    "    \"-c:a\", \"libopus\",\n",
    "    \"-b:a\", \"96k\",  # bitrate\n",
    "    \"edited_hit_the_floor.opus\"\n",
    "])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c21b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", \"q_edited_hit_the_floor.wav\",\n",
    "    \"-c:a\", \"libopus\",\n",
    "    \"-b:a\", \"96k\",  # bitrate\n",
    "    \"q_edited_hit_the_floor.opus\"\n",
    "])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39338ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_spec.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393a29b5",
   "metadata": {},
   "source": [
    "# Low Freq Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e90cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf3ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_bin_quantize(array):\n",
    "    \"\"\"\n",
    "    Vectorized log-bin quantization of a NumPy array.\n",
    "    Returns a single array of the same shape, where each value is\n",
    "    quantized to mantissa × 10^exponent, with mantissa having 3 sig. digits.\n",
    "    \"\"\"\n",
    "    abs_array = np.abs(array)\n",
    "\n",
    "    # Avoid log10(0) by masking zeros\n",
    "    mask_nonzero = np.all([abs_array < 0.001, abs_array > 0])\n",
    "\n",
    "    exponents = np.zeros_like(array, dtype=int)\n",
    "    mantissas = np.zeros_like(array, dtype=float)\n",
    "\n",
    "    # Compute exponents and mantissas\n",
    "    exponents[mask_nonzero] = np.floor(np.log10(abs_array[mask_nonzero])).astype(int)\n",
    "    mantissas[mask_nonzero] = abs_array[mask_nonzero] / (10. ** exponents[mask_nonzero])\n",
    "\n",
    "    # Quantize mantissas to 3 significant digits\n",
    "    mantissas = np.floor(mantissas * 1000) / 1000\n",
    "\n",
    "    # Reconstruct quantized values (preserving sign)\n",
    "    quantized = np.zeros_like(array, dtype=float)\n",
    "    quantized[mask_nonzero] = mantissas[mask_nonzero] * (10. ** exponents[mask_nonzero])\n",
    "    quantized[~mask_nonzero] = array[~mask_nonzero]\n",
    "    # quantized[~mask_nonzero] = 0.0  # Handle zeros explicitly\n",
    "\n",
    "\n",
    "    return quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.abs(total_spec.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4304cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc432f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "qspec = log_bin_quantize(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c120d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(qspec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c40377",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=raw, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fdc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped = librosa.istft(qspec, n_fft=n_fft//4, hop_length=hop_length//4, win_length=win_length//4, window=window, length=raw.shape[1])\n",
    "Audio(data=clipped, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = np.max(raw_spec)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(raw_spec.mean(axis=0)), ref=rp),\n",
    "                         y_axis='log', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554220d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = total_spec.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d614339",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5df184",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = np.zeros((spec.shape[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fae40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compress_spectrogram_with_anchors(spectrogram, threshold=2, match_tolerance=1e-2):\n",
    "    \"\"\"\n",
    "    Compress spectrogram columns by anchoring based on Euclidean distance from 0.\n",
    "    \n",
    "    Returns:\n",
    "    - anchors: dict of {int_distance: [(unique_id, column)]}\n",
    "    - compressed: list of (either full column or reference (anchor_id, unique_id))\n",
    "    \"\"\"\n",
    "    anchors = {}\n",
    "    compressed = []\n",
    "    next_id = 0  # Unique ID counter for columns\n",
    "\n",
    "    for t in range(spectrogram.shape[1]):\n",
    "        col = spectrogram[:, t]\n",
    "        dist = np.linalg.norm(col)\n",
    "        anchor_key = int(round(dist))\n",
    "\n",
    "        found = False\n",
    "        # Check nearby keys in anchor space\n",
    "        for nearby_key in range(anchor_key - threshold, anchor_key + threshold + 1):\n",
    "            if nearby_key in anchors:\n",
    "                for uid, ref_col in anchors[nearby_key]:\n",
    "                    diff = np.linalg.norm(col - ref_col)\n",
    "                    if diff <= match_tolerance:\n",
    "                        # Store a reference instead of full column\n",
    "                        compressed.append((\"ref\", nearby_key, uid))\n",
    "                        found = True\n",
    "                        break\n",
    "            if found:\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            # New anchor column, store full column and register in anchor map\n",
    "            if anchor_key not in anchors:\n",
    "                anchors[anchor_key] = []\n",
    "            anchors[anchor_key].append((next_id, col.copy()))\n",
    "            compressed.append((\"full\", anchor_key, next_id, col.copy()))\n",
    "            next_id += 1\n",
    "\n",
    "    return anchors, compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f49f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_spectrogram_with_anchors(spec, threshold=1000, match_tolerance=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd74308",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00590bac",
   "metadata": {},
   "source": [
    "# Stem-Split Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ca7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9bf984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use librosa to split the stems\n",
    "\n",
    "total_harm, total_perc = librosa.decompose.hpss(total_spec, margin=2)\n",
    "rp = np.max(np.abs(total_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e498685",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(total_harm[:, :, :300].mean(axis=0)), ref=rp),\n",
    "                         y_axis='log', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce66c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(total_perc[:, :, :300].mean(axis=0)), ref=rp),\n",
    "                         y_axis='log', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee269473",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_harmonic = librosa.istft(total_harm, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window, length=raw.shape[1])\n",
    "Audio(data=y_harmonic, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adf018",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_percussive = librosa.istft(total_perc, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window, length=raw.shape[1])\n",
    "Audio(data=y_percussive, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba158c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y_percussive+y_harmonic, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "soundfile.write(\"harm.wav\", y_harmonic.T, samplerate=sr)\n",
    "soundfile.write(\"perc.wav\", y_percussive.T, samplerate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795416b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f92cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", \"perc.wav\",\n",
    "    \"-c:a\", \"libopus\",\n",
    "    \"-b:a\", \"96k\",  # bitrate\n",
    "    \"perc.opus\"\n",
    "])\n",
    "print(\"\")\n",
    "\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", \"harm.wav\",\n",
    "    \"-c:a\", \"libopus\",\n",
    "    \"-b:a\", \"96k\",  # bitrate\n",
    "    \"harm.opus\"\n",
    "])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f46b22",
   "metadata": {},
   "source": [
    "# VAE-VQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663b634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db2e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3393cf3",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SNR Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SNR segment wise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
